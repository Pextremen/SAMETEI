#!/usr/bin/env python3
"""
DOT-OCR Service (GOT-OCR2) - Python servis mod√ºl√º
Geli≈ümi≈ü g√∂r√ºnt√º OCR i≈üleme i√ßin tasarlandƒ±
"""

import os
import sys
import json
import torch
import tempfile
from PIL import Image
from transformers import AutoModel, AutoTokenizer
import argparse
import logging
import time

# Logging konfig√ºrasyonu
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DotOCRService:
    def __init__(self, model_path=None):
        """
        DOT-OCR Service ba≈ülatƒ±cƒ±

        Args:
            model_path (str): GOT-OCR2 model dizini yolu
        """
        self.model_path = model_path or r"C:\Users\samet\Downloads\GOT-OCR2_0"
        self.model = None
        self.tokenizer = None
        self.is_initialized = False
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

        logger.info(f"DOT-OCR Service ba≈ülatƒ±lƒ±yor. Cihaz: {self.device}")

    def initialize_model(self):
        """GOT-OCR2 modelini y√ºkle ve ba≈ülat"""
        try:
            if not os.path.isdir(self.model_path):
                raise FileNotFoundError(f"Model dizini bulunamadƒ±: {self.model_path}")

            logger.info("Model y√ºkleniyor...")

            # Tokenizer y√ºkleme
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_path,
                local_files_only=True,
                trust_remote_code=True
            )

            # Model y√ºkleme
            self.model = AutoModel.from_pretrained(
                self.model_path,
                local_files_only=True,
                trust_remote_code=True,
                torch_dtype=torch.float16 if self.device == 'cuda' else torch.float32,
                device_map=self.device
            ).eval()

            # Generation config ayarlarƒ± - Timeout kaldƒ±rƒ±ldƒ±
            if hasattr(self.model, 'generation_config') and self.model.generation_config is not None:
                self.model.generation_config.use_cache = False
                # self.model.generation_config.max_new_tokens = 1024  # Kaldƒ±rƒ±ldƒ± - sƒ±nƒ±rsƒ±z
                self.model.generation_config.temperature = 0.0
                self.model.generation_config.do_sample = False
                self.model.generation_config.repetition_penalty = 1.0
                # GOT-OCR2 i√ßin √∂zel ayarlar
                if hasattr(self.model.generation_config, 'pad_token_id'):
                    pass  # Zaten ayarlandƒ±
                if hasattr(self.model.generation_config, 'eos_token_id'):
                    pass  # Zaten ayarlandƒ±

                # Pad/EOS token ayarlarƒ±
                eos_id = self.tokenizer.eos_token_id or self.tokenizer.convert_tokens_to_ids('</s>')
                if self.tokenizer.pad_token_id is None and eos_id is not None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token or '</s>'

                pad_id = self.tokenizer.pad_token_id or eos_id
                if pad_id is not None:
                    self.model.generation_config.pad_token_id = pad_id
                    self.model.generation_config.eos_token_id = eos_id

            # Config ayarlarƒ±
            if hasattr(self.model, 'config') and self.model.config is not None:
                self.model.config.use_cache = False
                if pad_id is not None:
                    self.model.config.pad_token_id = pad_id
                    self.model.config.eos_token_id = eos_id

            self.is_initialized = True
            logger.info("‚úÖ Model ba≈üarƒ±yla y√ºklendi!")
            logger.info(f"üìç Cihaz: {self.device}")
            if self.device == 'cuda':
                logger.info(f"üéÆ GPU: {torch.cuda.get_device_name(0)}")

            return True

        except Exception as e:
            logger.error(f"‚ùå Model y√ºkleme hatasƒ±: {e}")
            return False

    def _resize_image(self, image_path, long_edge_max=1600):
        """G√∂r√ºnt√ºy√º hƒ±z optimizasyonu i√ßin yeniden boyutlandƒ±r"""
        try:
            img = Image.open(image_path).convert('RGB')
            w, h = img.size
            long_edge = max(w, h)

            if long_edge <= long_edge_max:
                return image_path

            scale = long_edge_max / float(long_edge)
            new_w, new_h = max(1, int(w * scale)), max(1, int(h * scale))
            img = img.resize((new_w, new_h))

            # Ge√ßici dosya olu≈ütur
            temp_dir = os.path.join(os.path.dirname(image_path), "_runtime")
            os.makedirs(temp_dir, exist_ok=True)
            temp_path = os.path.join(temp_dir, f"resized_{int(time.time())}.png")
            img.save(temp_path, format='PNG')

            return temp_path

        except Exception as e:
            logger.warning(f"G√∂r√ºnt√º yeniden boyutlandƒ±rma hatasƒ±: {e}")
            return image_path

    def _get_extraction_prompt(self, extraction_type='table_text_tsv'):
        """Basitle≈ütirilmi≈ü prompt - doƒüal metin √ßƒ±karƒ±mƒ±"""
        base_prompt = (
            "Bu g√∂r√ºnt√ºdeki T√úM metinleri oku ve √ßƒ±kar. "
            "Tablolar, formlar, dikey yazƒ±lmƒ±≈ü metinler varsa hepsini oku ama kelimeleri ASLA harflere b√∂lme. "
            "Dikey s√ºtunlar varsa s√ºtun-s√ºtun oku fakat kelimeleri b√∂lmeden ve satƒ±r sonlarƒ±nda kelimeleri par√ßalama. "
            "Renkli arka planlƒ± metinleri de ihmal etme. "
            "Gri veya farklƒ± tonlardaki metinleri de oku. "
            "Metni doƒüal, okunabilir ve kelime sƒ±nƒ±rlarƒ± korunmu≈ü ≈üekilde √ßƒ±kar. "
            "Hi√ßbir metni atlama."
        )

        if extraction_type == 'table_text_tsv':
            return base_prompt + " Tablo yapƒ±sƒ±nƒ± mantƒ±klƒ± ≈üekilde koru."
        elif extraction_type == 'form':
            return base_prompt + " Form alanlarƒ±nƒ± ve deƒüerlerini a√ßƒ±k ≈üekilde belirt."
        elif extraction_type == 'text_only':
            return base_prompt + (
                " Her metin BLOƒûUNU ayrƒ± satƒ±rda d√∂nd√ºr. "
                "Bir blok i√ßindeki kelimeleri birle≈ütir ama farklƒ± b√∂lgeler birbirine yapƒ±≈ümasƒ±n."
            )
        else:
            return base_prompt

    def extract_text(self, image_path, extraction_type='table_text_tsv', custom_prompt=None):
        """
        G√∂r√ºnt√ºden metin √ßƒ±kar

        Args:
            image_path (str): G√∂r√ºnt√º dosya yolu
            extraction_type (str): √áƒ±karƒ±m t√ºr√º
            custom_prompt (str): √ñzel prompt (varsa)

        Returns:
            dict: √áƒ±karƒ±m sonucu
        """
        try:
            if not self.is_initialized:
                if not self.initialize_model():
                    return {
                        'success': False,
                        'error': 'Model ba≈ülatƒ±lamadƒ±',
                        'text': ''
                    }

            # G√∂r√ºnt√º kontrol√º
            if not os.path.exists(image_path):
                return {
                    'success': False,
                    'error': f'G√∂r√ºnt√º bulunamadƒ±: {image_path}',
                    'text': ''
                }

            logger.info(f"üì∑ G√∂r√ºnt√º y√ºkleniyor: {os.path.basename(image_path)}")

            # G√∂r√ºnt√º y√ºkleme kontrol√º
            _ = Image.open(image_path)

            # Hƒ±z optimizasyonlarƒ±
            if torch.cuda.is_available():
                torch.set_float32_matmul_precision('high')
                try:
                    torch.backends.cuda.matmul.allow_tf32 = True
                except:
                    pass

            # G√∂r√ºnt√ºy√º yeniden boyutlandƒ±r
            resized_path = self._resize_image(image_path, long_edge_max=1600)

            # Prompt olu≈ütur
            prompt = custom_prompt or self._get_extraction_prompt(extraction_type)

            logger.info(f"üîç OCR i≈ülemi ba≈ülatƒ±lƒ±yor ({extraction_type})...")

            start_time = time.time()

            with torch.inference_mode():
                try:
                    # GOT-OCR2 i√ßin basit metin √ßƒ±karƒ±mƒ±
                    result = self.model.chat(
                        self.tokenizer,
                        resized_path,
                        question=prompt
                    )
                except TypeError:
                    try:
                        result = self.model.chat(
                            self.tokenizer,
                            resized_path,
                            question=prompt
                        )
                    except TypeError:
                        # Son √ßare: prompt'suz
                        result = self.model.chat(
                            self.tokenizer,
                            resized_path,
                            ocr_type='ocr'
                        )

            processing_time = time.time() - start_time

            # Ge√ßici dosyayƒ± temizle
            if resized_path != image_path and os.path.exists(resized_path):
                try:
                    os.unlink(resized_path)
                    # _runtime klas√∂r√ºn√º de temizle
                    runtime_dir = os.path.dirname(resized_path)
                    if os.path.exists(runtime_dir) and not os.listdir(runtime_dir):
                        os.rmdir(runtime_dir)
                except:
                    pass

            logger.info(f"‚úÖ OCR tamamlandƒ±: {len(result)} karakter, {processing_time:.2f}s")

            return {
                'success': True,
                'text': result,
                'extraction_type': extraction_type,
                'processing_time': processing_time,
                'model': 'GOT-OCR2',
                'device': self.device
            }

        except Exception as e:
            logger.error(f"‚ùå OCR hatasƒ±: {e}")
            return {
                'success': False,
                'error': str(e),
                'text': '',
                'extraction_type': extraction_type
            }

def main():
    """Komut satƒ±rƒ± aray√ºz√º"""
    parser = argparse.ArgumentParser(description='DOT-OCR Service')
    parser.add_argument('image_path', help='ƒ∞≈ülenecek g√∂r√ºnt√º dosyasƒ±')
    parser.add_argument('--type', default='table_text_tsv',
                       choices=['table_text_tsv', 'form', 'text_only', 'structured'],
                       help='√áƒ±karƒ±m t√ºr√º')
    parser.add_argument('--model-path', help='GOT-OCR2 model dizini yolu')
    parser.add_argument('--custom-prompt', help='√ñzel prompt')
    parser.add_argument('--output', '-o', help='√áƒ±ktƒ± dosyasƒ± (JSON)')

    args = parser.parse_args()

    # Servis ba≈ülat
    service = DotOCRService(args.model_path)

    # OCR i≈üle
    result = service.extract_text(
        args.image_path,
        args.type,
        args.custom_prompt
    )

    # Sonu√ß
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"Sonu√ß {args.output} dosyasƒ±na kaydedildi")
    else:
        print(json.dumps(result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()
